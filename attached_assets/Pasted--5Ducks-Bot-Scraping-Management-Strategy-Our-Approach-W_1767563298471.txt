# 5Ducks Bot & Scraping Management Strategy

## Our Approach

We're opening up SEO pages (`/company/:slug/:id` and `/p/:slug/:id`) to drive organic traffic. This means managing bot access carefully.

---

## Bot Policy

### ALLOW — AI Bots (for citations/visibility)
- GPTBot, ChatGPT-User (OpenAI)
- ClaudeBot, anthropic-ai (Anthropic)
- Bytespider (ByteDance)
- PerplexityBot (Perplexity)
- Google-Extended (Gemini)

**Why:** We want AI assistants to reference 5Ducks when users ask about companies/contacts. This drives awareness and signups.

### BLOCK — AI Training-Only Bots (no citation value)
- CCBot (Common Crawl)
- Meta-ExternalAgent (Meta internal)
- Diffbot (data reseller)
- Cohere-ai, YouBot, etc.

### BLOCK — SEO Tool Bots (competitor intelligence)
- SemrushBot
- AhrefsBot
- MJ12bot (Majestic)
- DotBot, Rogerbot (Moz)

**Why:** These only help competitors analyze us. No benefit to us.

---

## Protection Layers

### Layer 1: robots.txt
- Politely requests bots to follow our rules
- Works for reputable bots (Google, OpenAI, Anthropic)
- Ignored by malicious scrapers
- **Effort:** Low (just a text file)

### Layer 2: Rate Limiting (Express)
- Limit requests per IP to `/company/` and `/p/` routes
- Prevents any single source from overwhelming server
- **Suggested:** 30 requests/minute per IP for SEO pages
- **Effort:** Medium (add express-rate-limit middleware)

### Layer 3: User-Agent Blocking (Server Level)
- Block known bad bots at Nginx/server level
- More efficient than application-level blocking
- Bots never reach our app code
- **Effort:** Medium (Nginx config changes)

### Layer 4: Cloudflare (Recommended)
- Sits in front of server — bad traffic never reaches us
- ML-based bot detection (catches spoofed user agents)
- Built-in DDoS protection
- WAF rules for granular control
- **Effort:** Low-Medium (DNS change + configuration)
- **Cost:** Free tier available, Pro is $20/month

---

## Implementation Plan

### Phase 1: Before SEO Launch (Minimum)
1. Update robots.txt with our bot policy
2. Add rate limiting to Express for `/company/` and `/p/` routes

### Phase 2: At SEO Launch (Recommended)
3. Put Cloudflare in front of 5ducks.ai
4. Enable Cloudflare's "Bot Fight Mode"
5. Add WAF rules to block SEO tool bots

### Phase 3: If We See Abuse
6. Upgrade Cloudflare for advanced bot management
7. Add JS challenges for suspicious traffic
8. IP-based blocking for repeat offenders

---

## Key Points

- **robots.txt is not security** — it's a request, not enforcement
- **AI bots = good for us** — we want citations in ChatGPT/Claude responses
- **SEO bots = bad for us** — only helps competitors
- **Rate limiting is essential** — even allowed bots can overwhelm our server
- **Cloudflare is the best protection** — catches bots that lie about who they are